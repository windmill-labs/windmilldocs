# Postgres triggers in windmill

Windmill can connect to a [Postgres](https://www.postgres.org/) database and trigger runnables (scripts, flows) in response to database transactions (INSERT, UPDATE, DELETE) on specified tables, schemas, or the entire database.  
Listening is done using Postgres's **logical replication streaming protocol**, ensuring efficient and low-latency triggering.  
Listening is done from the servers, so it doesn't take up any workers.
Postgres triggers are not available on the [Cloud](/pricing).

---

## 1. Introduction

### What is logical replication?

Windmill's Postgres trigger feature is built on **Postgres's logical replication protocol**, which allows changes to a database to be streamed in real time to subscribers. Logical replication provides fine-grained control over what data is replicated by allowing the user to define **publications** and subscribe to specific changes.

#### How Logical Replication Works:
1. **Publications**: Define what changes (e.g., INSERT, UPDATE, DELETE) should be made available for replication. Publications allow you to select specific tables or schemas to track.
2. **Replication Slots**: Ensure that all changes from a publication are retained until they are successfully delivered to the subscriber (e.g., Windmill triggers). This guarantees data reliability and prevents data loss.

Windmill uses logical replication to efficiently stream database changes to your configured triggers, ensuring minimal latency and high reliability.

For more details, see the [Postgres documentation on logical replication](https://www.postgres.org/docs/current/logical-replication.html).\
For more details, see the [Postgres documentation on logical replication streaming protocol](https://www.postgres.org/docs/current/protocol-logical-replication.html).

---

## 2. How to use

### Create a Postgres trigger
To begin, navigate to the Postgres triggers page and create a new trigger. Follow the steps below to set up your environment.

### Set Up a Postgres resource
You need to either:
- **Create a new Postgres resource** by providing:
  - Hostname, port, database name, username, and password.
  - Advanced options such as SSL settings if needed.
- **Reuse an existing Postgres resource**.

### Define what to track
Once the Postgres resource is configured, you can choose what to track.

#### All tables
The trigger will listen for transactions on **all tables** in the database.

**Example:**

![Track all tables example](./track_all_tables.png 'Track all tables example')

#### Specific schemas
The trigger will listen for transactions on all tables within the selected schemas. Any new tables added to these schemas in the future will also be tracked automatically.

**Example:**
Tracking the `public` and `marketing` schemas:

![Track specific schemas example](./track_specific_schemas_marketing_public.png 'Track specific schemas: marketing and public')

#### Specific tables
The trigger will listen only for transactions on the specified tables. You can also choose which **columns** to retrieve when tracking specific tables.

**Example:**
In this setup, the `bakery` table in the `paris` schema is tracked, but only the `name` and `address` columns are retrieved.

![Track specific tables example](./track_specific_tables_bakery.png 'Track specific tables: user and bakery')

---

## 3. Limitations and examples

### Valid configuration
You **can** combine:
- Schema-level tracking (e.g., `public` schema).
- Specific table tracking **without selecting columns**.

**Example:**
Tracking the `bakery` table in the `paris` schema and all tables in the `private` and `public` schemas:

![Valid configuration example](./valid_config.png 'Valid configuration example')

### Invalid configuration
You **cannot** combine:
- Schema-level tracking with specific table tracking **that includes column selection**.

**Example:**
Tracking all tables in the `public` schema **and** the `bakery` table in the `paris` schema with selected columns (`name` and `address`):

![Invalid configuration example](./invalid_config.png 'Invalid configuration example')

---

## 4. Additional options

### Filtering rows with WHERE condition
When tracking specific tables, you can filter rows by providing a **WHERE condition**.

**Key notes:**
- The `WHERE` clause allows only **simple expressions**.
- It **cannot** contain:
  - User-defined functions, operators, types, and collations.
  - System column references.
  - Non-immutable built-in functions.

**Important:**
- You **only need to provide the condition**, not the entire `WHERE` clause. For example, instead of writing `WHERE speciality = 'croissant'`, just provide the condition: `speciality = 'croissant'`.
- If your trigger is set to track `UPDATE` and/or `DELETE` transactions, the `WHERE` clause **can only reference columns that are part of the table’s replica identity**.  
  See the [REPLICA IDENTITY documentation](https://www.postgres.org/docs/current/sql-altertable.html#SQL-ALTERTABLE-REPLICA-IDENTITY) for more details.
- If your trigger tracks only `INSERT` transactions, the `WHERE` clause can reference **any column**.

For more details, refer to the [Postgres WHERE clause documentation](https://www.postgres.org/docs/current/logical-replication-row-filter.html#LOGICAL-REPLICATION-ROW-FILTER-RESTRICTIONS).

**Illustration:**
Here’s an example showing how to filter rows based on the condition `speciality = 'croissant'` in the `bakery` table of the `paris` schema:

![Where condition example](./where_condition_paris_bakery.png 'Filtering rows example: speciality = croissant')

---

### Selecting specific columns
For specific tables, you can reduce the data sent to the triggered runnable by retrieving only the columns you need.

**Example:**
In the `paris` schema, you can track the `bakery` table but only retrieve the `name` and `address` columns.

**Illustration:**

![Column selection example](./column_selection_paris_bakery.png 'Column selection example: name and address')

---

## 5. Advanced

### Managing Postgres publications
By default, Windmill automatically creates a **publication** and a **replication slot** for you when setting up a trigger. However, in the **Advanced** section, you can:

- **Create a custom publication**: If you prefer to use your own publication, you can create it directly from the interface.
    - Example: Create a publication named `windmill_publication_sincere`, which tracks **all tables** in the `public` and `private` schemas, and is set to track only **update** and **delete transactions**.

      ![Creating publication example](./create_publication_example.png 'Create a custom publication: windmill_publication_illuminating')

- **Choose an existing publication**: Instead of relying on the default publication created by Windmill, you can select an existing publication from your database to use for your trigger.
    - For example, when retrieving the publication `windmill_publication_non_violent`, **all tables** are tracked, and the publication tracks **insert, update, and delete transactions** by default.
    - In the image below, the **tracked tables** and **insert transaction** type for the publication are displayed. You can use the publication as is or:
      - **Update the publication** by adding or removing tables and schemas being tracked, or modifying the transaction types.
      - **Delete the publication** if no longer needed.

      ![Retrieving and managing publication example](./retrieve_publication_example.png 'Retrieve and manage publication: windmill_publication_non_violent')

For more information on **Postgres publications**, refer to the [Postgres documentation on publications](https://www.postgres.org/docs/current/logical-replication-publication.html).

---

### Managing Postgres replication slots
In the **Advanced** section, you can also manage your **replication slots**. Windmill will automatically create a replication slot for you by default, but you can interact with replication slots as follows:

- **Create a custom replication slot**: If needed, you can create your own replication slot directly in the interface.
- **Choose an existing replication slot**: You can select an existing replication slot from your database and link it to the trigger.
- **Delete a replication slot**: If a replication slot is no longer necessary, you can delete it through the interface.

---

## 6. Creating a script from tracked tables

Windmill enables you to **automatically generate a script template** for specific tables and/or schemas tracked by a trigger. This feature simplifies the creation of a TypeScript script with the necessary structure to handle data passed by the trigger.

### Prerequisites

- **Postgres Resource**: A Postgres resource must be configured in your environment to enable this feature.
- **At Least One Schema**: You need to select at least one schema to track.
- **Specific Tables and/or Schema**: This feature works **only for specific tables and/or schemas**. Make sure your selection matches the criteria for script generation.

### How to use

1. **Set up Postgres Resource**: Ensure that a Postgres resource is configured in the resources page.

2. **Select Schema and Tables**: Choose the schema and tables you want to track. Note that this feature does not work for all tables; only those meeting the criteria for tracking will be available.

3. **Click on "Create from Template"**: After selecting the desired tables and schemas, click on the **Create from Template** button. This will open a new tab containing a **TypeScript** script.

   - The script will include a **main function** that takes an argument representing the information sent to the script. This argument is a **JSON object** structured as follows:

```json
{
  "transaction_type": "insert" | "update" | "delete",
  "schema_name": "string",
  "table_name": "string",
  "row": {
    ...
  }
}
```
### Explanation of fields

- **transaction_type**: Specifies the type of change (either `insert`, `update`, or `delete`).
- **schema_name**: The name of the schema being tracked (type: `string`).
- **table_name**: The name of the table being tracked (type: `string`).
- **row**: Contains the data of the row involved in the transaction. The data type of each field in `row` depends on the column's data type in the Postgres table.

#### Example table schema

Consider a table `users` in the **public** schema with the following SQL definition:

```sql
CREATE TABLE users (
    id SERIAL PRIMARY KEY, 
    name VARCHAR(100) NOT NULL,
    lastname VARCHAR(100) NOT NULL,
    age INT CHECK (age > 0),
    personal_information JSONB,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP NOT NULL,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP NOT NULL
);
```
For this schema, the corresponding **row** in the JSON object would look like this:

```json
{
    row: {
		id?: number,
		name?: string,
		lastname?: string,
		age: number,
		personal_information: unknown,
		created_at?: Date,
		updated_at?: Date,
	}
}
```
### Key notes

- **Transaction Types**: The `transaction_type` field in the JSON object can be one of `insert`, `update`, or `delete`, depending on the change type in the tracked table.
- **Row Data**: The `row` field contains the data of the specific table or schema, and can be used directly in your script for processing.

### Script template example

Once the template is generated, you can modify it to meet your needs. Below is an example of the generated script template, based on a sample transaction, with a `users` table in the **public** schema.

```typescript
  export async function main(
  transaction_type: "insert" | "update" | "delete",
  schema_name: string,
  table_name: string,
  row: {
		id?: number,
		name?: string,
		lastname?: string,
		age: number,
		personal_information: unknown,
		created_at?: Date,
		updated_at?: Date,
	}
) {
}
```