import DocCard from '@site/src/components/DocCard';

# Windmill AI

Windmill provides ways to have AI help you in your coding experience.

:::info OpenAI integration

If you're rather interested in leveraging OpenAI from your scripts, flows and apps, check [OpenAI Integration](../../integrations/openai.md).

:::

To enable Windmill AI, go to the "Windmill AI" tab in the workspace settings and add a [supported model](#models)'s [resource](../3_resources_and_types/index.mdx). Code completion is disabled by default, but you can enable it in the same tab.

![Enable Windmill AI](./enable_ai.png 'Enable Windmill AI')

## Windmill AI for scripts

### AI Chat

The script editor includes an integrated AI chat panel designed to assist with coding tasks directly. 
The assistant can generate code, identify and fix issues, suggest improvements, add documentation, and more.

Key features include:

- **Granular Apply/Reject**: When the AI suggests code changes, you can apply or discard specific parts of the suggestion, rather than having to accept or reject the entire block.
- **Contextual Awareness**: You can provide additional context to guide the AIâ€™s suggestions, such as database schemas, diffs from the deployed version, or runtime errors.
- **Quick Actions**: The panel includes built-in shortcuts for common tasks like fixing bugs or optimizing code, making it faster to apply standard improvements.

<video
	className="border-2 rounded-lg object-cover w-full h-full dark:border-gray-800"
	controls
	src="/videos/ai_chat.mp4"
/>

### Code completion

The script editor includes code autocomplete using AI. Pressing Tab completes code snippets based on neighboring context, not just at the cursor.

It can be enabled/disabled at the user level in the script editor settings.

<video
	className="border-2 rounded-lg object-cover w-full h-full dark:border-gray-800"
	controls
	src="/videos/ai_autocomplete.mp4"
/>


### Summary copilot

From your code, the AI assistant can generate a script summary.

<video
	className="border-2 rounded-lg object-cover w-full h-full dark:border-gray-800"
	controls
	src="/videos/summary_compilot.mp4"
/>

### Legacy AI features

The following guides are still applicable for code editing of inline scripts inside flows and apps.

#### Code generation

<video
	className="border-2 rounded-lg object-cover w-full h-full dark:border-gray-800"
	controls
	src="/videos/ai_generation.mp4"
/>

<br />

In a [code editor](../../code_editor/index.mdx) (Script, Flow, Apps), click on `AI` and write a prompt describing what the script should do. The script will follow Windmill's main requirements and features (exposing a main function, importing libraries, using resource types, declaring required parameters with types). Moreover, when creating an SQL or GraphQL script, the AI assistant will take into account the database/GraphQL API schema **when selected**.

![Prompt](../../assets/code_editor/ai_gen.png 'Prompt')

:::tip Pro tips
The AI assistant is particularly effective when generating Python and TypeScript (Bun runtime) scripts, so we recommend using these languages when possible.
Moreover, you will get better results if you specify in the prompt what the script should take as parameters, what it should return, the specific integration and libraries it should use if any.
For instance, in the demo video above we wanted to generate a script that fetches the commits of a GitHub repository passed as a parameter, so we wrote: `fetch and return the commits of a given repository on GitHub using octokit`.
:::

#### Code editing

Inside the `AI Gen` popup, you can choose to edit the existing code rather than generating a new one. The assistant will modify the code according to your prompt.

<video
	className="border-2 rounded-lg object-cover w-full h-full dark:border-gray-800"
	controls
	src="/videos/ai_edit.mp4"
/>

#### Code fixing

Upon error when executing code, you will be offered to "AI Fix" it. The assistant will automatically read the code, explain what went wrong, and suggest a way to fix it.

<video
	className="border-2 rounded-lg object-cover w-full h-full dark:border-gray-800"
	controls
	src="/videos/ai_fix.mp4"
/>


## Windmill AI for flows

Generate Workflows from prompts.

Windmill AI for Flows support two creation modes: Sequence Flows and Trigger Flows.
In both cases, you specify a prompt for each step. The AI assistant will then generate the code step by step and link them together.
You will have the opportunity at the end of each step to review, edit or even regenerate the step's code.

For each action, you can either choose a script from the [Hub](https://hub.windmill.dev/) or generate one from scratch using Windmill AI.
At the end of the process, flow inputs are inferred and you just need to fill them in.

<div className="grid grid-cols-2 gap-6 mb-4">
	<DocCard
		title="Blog - Flow Builder Copilot"
		description="Details on how the Flow Builder Copilot was built"
		href="/blog/launch-week-1/ai-flow-builder"
	/>
</div>

### Sequence flows

Generate a flow consisting of a sequence of scripts.

<iframe
	style={{ aspectRatio: '16/9' }}
	src="https://www.youtube.com/embed/y-pV6CShdZA"
	title="YouTube video player"
	frameBorder="0"
	allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
	allowFullScreen
	className="border-2 rounded-lg object-cover w-full dark:border-gray-800"
></iframe>

### Trigger flows

[Trigger flows](../../flows/10_flow_trigger.mdx) are designed to pull data from an external source and return all of the new items since the last run, without resorting to external webhooks. A trigger script is intended to be used as scheduled poll with [schedules](../1_scheduling/index.mdx) and [states](../3_resources_and_types/index.mdx#states) (rich objects in JSON, persistent from one run to another) in order to compare the execution to the previous one and process each new item in a [for loop](../../flows/12_flow_loops.md).

If there are no new items, the flow will be skipped.

<iframe
	style={{ aspectRatio: '16/9' }}
	src="https://www.youtube.com/embed/4HTIKOAyVIg"
	title="YouTube video player"
	frameBorder="0"
	allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
	allowFullScreen
	className="border-2 rounded-lg object-cover w-full dark:border-gray-800"
></iframe>

<br />

The inputs of the for-loop action are automatically filled in with the outputs of the trigger step.

Moreover, the flow is automatically set to run every 15 minutes when deployed. The [schedule](../1_scheduling/index.mdx) can then be customized (e.g. every 30 seconds etc.).
This allows you to avoid relying on webhooks sent by external APIs, which can be tedious to configure.

<div className="grid grid-cols-2 gap-6 mb-4">
	<DocCard
		title="Trigger scripts"
		description="Trigger scripts are designed to pull data from an external source and return all of the new items since the last run, without resorting to external webhooks."
		href="/docs/flows/flow_trigger"
	/>
</div>

### Summary copilot for steps

From your code, the AI assistant can generate a summary for flow steps.

<video
	className="border-2 rounded-lg object-cover w-full h-full dark:border-gray-800"
	controls
	src="/videos/summary_copilot_steps.mp4"
/>

### Step input copilot

When adding a new step to a flow, the AI assistant will suggest inputs based on the previous steps' results and flow inputs.

<video
	className="border-2 rounded-lg object-cover w-full h-full dark:border-gray-800"
	controls
	src="/videos/step_input_copilot.mp4"
/>

### Flow loops iterator expressions from context

When adding a [for loop](../../flows/12_flow_loops.md), the AI assistant will suggest iterator expressions based on the previous steps' results.

<video
	className="border-2 rounded-lg object-cover w-full h-full dark:border-gray-800"
	controls
	src="/videos/iterator_prefill.mp4"
/>

### Flow branches predicate expressions from prompts

When adding a [branch](../../flows/13_flow_branches.md), the AI assistant will suggest predicate expressions from a prompt.

<video
	className="border-2 rounded-lg object-cover w-full h-full dark:border-gray-800"
	controls
	src="/videos/branch_predicate_copilot.mp4"
/>

## CRON schedules from prompt

The AI assistant can generate CRON [schedules](../1_scheduling/index.mdx) from a prompt.

<video
	className="border-2 rounded-lg object-cover w-full h-full dark:border-gray-800"
	controls
	src="/videos/cron_from_prompt.mp4"
/>

## Models

Windmill AI supports:
- OpenAI's [models](https://platform.openai.com/docs/models) (o1 currently not supported)
- Azure OpenAI's [models](https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models)
	- Base URL format: `https://{your-resource-name}.openai.azure.com/openai/deployments/{deployment-id}`
- Anthropic's [models](https://docs.anthropic.com/en/docs/about-claude/models/all-models) (including Claude 3.7 Sonnet in extended thinking mode)
- Mistral's [Codestral](https://mistral.ai/technology/#models)
- DeepSeek's [models](https://api-docs.deepseek.com/quick_start/pricing)
- Google's [Gemini models](https://ai.google.dev/models/gemini)
- Groq's [models](https://console.groq.com/docs/models)
- OpenRouter's [models](https://openrouter.ai/models)
- Together AI's [models](https://docs.together.ai/docs/serverless-models)
- Custom AI: base URL and API key of any AI provider that is OpenAI API-compatible

If you'd like to use a model that isn't in the default dropdown list, you can use any model supported by a provider (like `gpt-4o-2024-05-13` or `claude-3-7-sonnet-20250219`) by simply typing the model name in the model input field and pressing enter.

### AWS Bedrock

For models hosted on AWS Bedrock, you can use the `Custom AI` provider and follow the instructions in the [Windmill AI using AWS Bedrock](/docs/misc/9_guides/aws_bedrock/index.mdx) guide.